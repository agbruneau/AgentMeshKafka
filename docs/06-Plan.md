# Plan d'Impl√©mentation - Projet AgentMeshKafka

> **Version :** 1.0.0 | **Statut :** En cours | **Derni√®re r√©vision :** Janvier 2026
>
> **Documents connexes :** [00-Readme.md](./00-Readme.md) | [07-Constitution.md](./07-Constitution.md)

Ce document sert de **Feuille de Route (Roadmap)** pour l'ex√©cution du projet. Il est divis√© en phases logiques, allant de l'infrastructure (Syst√®me Nerveux) vers l'intelligence (Cerveau) et la validation (Syst√®me Immunitaire), suivant une approche it√©rative **"Bottom-Up"**.
**Objectif :** Livrer un POC fonctionnel d√©montrant l'interop√©rabilit√© d'agents autonomes via un backbone Kafka s√©curis√©.

---

## üìÖ Phase 0 : Initialisation & Environnement

**Objectif :** Mettre en place le socle technique et les outils de d√©veloppement.

* [ ] **0.1 Setup Repository**
* [ ] Initialiser Git (`git init`).
* [ ] Cr√©er la structure de dossiers (`docs/`, `src/`, `schemas/`, `tests/`).
* [ ] R√©diger le `README.md` initial.


* [ ] **0.2 Infrastructure Locale (Docker)**
* [ ] Configurer `docker-compose.yml` (Zookeeper, Kafka Broker, Schema Registry, Control Center).
* [ ] V√©rifier la bonne sant√© des conteneurs (`docker ps`).


* [ ] **0.3 Environnement Python**
* [ ] Cr√©er un `virtualenv`.
* [ ] D√©finir `requirements.txt` (confluent-kafka, langchain, pydantic, openai, pytest, chromadb).
* [ ] Configurer les variables d'environnement (`.env`) pour les cl√©s API.



---

## üß† Phase 1 : Le Syst√®me Nerveux (Data & Kafka)

**Objectif :** √âtablir les contrats d'interface stricts avant de coder l'intelligence. *Schema-First Design.*

* [ ] **1.1 D√©finition des Sch√©mas (Avro)**
* [ ] R√©diger `schemas/loan_application.avsc` (Demande).
* [ ] R√©diger `schemas/risk_assessment.avsc` (Risque).
* [ ] R√©diger `schemas/loan_decision.avsc` (D√©cision).


* [ ] **1.2 Enregistrement & Topologie**
* [ ] Cr√©er un script `scripts/init_kafka.py` pour cr√©er les Topics avec les bonnes r√©tentions.
* [ ] Enregistrer les sch√©mas dans le Schema Registry local.


* [ ] **1.3 G√©n√©ration de Code**
* [ ] G√©n√©rer les classes Python (Pydantic models) √† partir des fichiers Avro pour assurer le typage dans le code.



---

## ü§ñ Phase 2 : Le Cerveau (D√©veloppement des Agents)

**Objectif :** Impl√©menter la logique cognitive des 3 agents selon le pattern ReAct.

* [ ] **2.1 Agent Intake (Le Gatekeeper)**
* [ ] Impl√©menter le Consumer (Source externe) et le Producer (Kafka).
* [ ] Ajouter la validation structurelle (Pydantic).
* [ ] *Livrable :* L'agent publie un JSON valide dans `finance.loan.application.v1`.


* [ ] **2.2 Base de Connaissance (RAG)**
* [ ] Cr√©er une base vectorielle (ChromaDB locale).
* [ ] Ing√©rer le document PDF "Politique de Cr√©dit" (chunking + embedding).
* [ ] Cr√©er l'outil de recherche `search_credit_policy`.


* [ ] **2.3 Agent Risk Analyst (Le Coeur Cognitif)**
* [ ] Configurer LangChain/LangGraph avec le System Prompt "Analyste".
* [ ] Connecter les outils : RAG + Calculatrice.
* [ ] Impl√©menter la boucle de consommation Kafka  R√©flexion  Production.


* [ ] **2.4 Agent Loan Officer (Le D√©cideur)**
* [ ] Impl√©menter la logique de d√©cision finale (Seuils d'approbation).
* [ ] Publier la d√©cision finale.



---

## üõ°Ô∏è Phase 3 : Le Syst√®me Immunitaire (AgentOps & Sec)

**Objectif :** S√©curiser et fiabiliser le maillage (Passage du POC √† la "Prod acad√©mique").

* [ ] **3.1 Tests Unitaires & Int√©gration**
* [ ] √âcrire les tests pour les outils (calculs math√©matiques).
* [ ] √âcrire les tests de s√©rialisation/d√©s√©rialisation Avro.


* [ ] **3.2 Pipeline d'√âvaluation (Le Diamant)**
* [ ] Configurer "LLM-as-a-Judge" (ex: via DeepEval).
* [ ] Cr√©er un dataset de 10 cas de tests (Golden Dataset).
* [ ] Ex√©cuter l'√©valuation de factualit√© sur l'Agent Risque.


* [ ] **3.3 Garde-fous (Security)**
* [ ] Impl√©menter la validation des inputs (Nettoyage XML/HTML).
* [ ] Tester une injection de prompt simple ("Ignore instructions").



---

## üöÄ Phase 4 : Orchestration & D√©monstration

**Objectif :** Prouver que le syst√®me fonctionne de bout en bout.

* [ ] **4.1 Script de Simulation**
* [ ] Cr√©er `scripts/simulate_traffic.py` pour injecter 50 demandes vari√©es.


* [ ] **4.2 Observabilit√©**
* [ ] Mettre en place un logging structur√© pour suivre la `trace_id` √† travers les 3 agents.
* [ ] (Optionnel) Visualiser les flux dans Confluent Control Center.


* [ ] **4.3 Rapport Final**
* [ ] Compiler les r√©sultats des tests d'√©valuation.
* [ ] R√©diger la conclusion du projet acad√©mique.



---

## üì¶ Livrables Finaux

1. Code source complet (GitHub).
2. Documentation technique (`/docs`).
3. Rapport d'ex√©cution des tests (Preuve de fiabilit√©).
4. Vid√©o/D√©mo du flux de donn√©es en temps r√©el.

---

## üìö Navigation

| ‚¨ÖÔ∏è Pr√©c√©dent | üè† Index | ‚û°Ô∏è Suivant |
|:---|:---:|---:|
| [05-ThreatModel.md](./05-ThreatModel.md) | [Documentation](./00-Readme.md#-documentation-compl√®te) | [07-Constitution.md](./07-Constitution.md) |